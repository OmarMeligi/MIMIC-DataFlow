#  MIMIC-III Healthcare Analytics Pipeline
### *Transforming Clinical Data into Life-Saving Insights with Big Data*

<div align="center">

![Epic Header](https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=300&section=header&text=Healthcare%20Analytics&fontSize=70&fontColor=white&animation=twinkling&fontAlignY=35&desc=Hadoop%20â€¢%20Hive%20â€¢%20MapReduce%20â€¢%20Clinical%20Intelligence&descAlignY=55&descSize=20)


</div>


---

##  **ARCHITECTURE**

<div align="center">

```mermaid
graph TB
    subgraph " MIMIC-III DATA SOURCES"
        A1[ PATIENTS_T.csv<br/>Patient Demographics]
        A2[ ADMISSIONS_T.xlsx<br/>Hospital Admissions]
        A3[ DIAGNOSES_ICD_T.xlsx<br/>Medical Diagnoses]
        A4[ ICUSTAYS_T.xlsx<br/>ICU Records]
        A5[ D_ICD_DIAGNOSES_T.xlsx<br/>Diagnosis Codes]
    end
    
    subgraph " DATA CLEANSING LAYER"
        B1[ Python ETL Scripts<br/>Data Transformation]
        B2[ Parquet Conversion<br/>Optimized Storage]
        B3[ Data Validation<br/>Quality Assurance]
    end
    
    subgraph "ğŸ—„ HADOOP ECOSYSTEM"
        C1[ HDFS Storage<br/>Distributed File System]
        C2[ Hive Tables<br/>Data Warehouse]
        C3[ MapReduce Jobs<br/>Custom Analytics]
    end
    
    subgraph " ANALYTICS & INSIGHTS"
        D1[ Hospital Length of Stay<br/>Per Diagnosis Analysis]
        D2[ ICU Readmissions<br/>Pattern Recognition]
        D3[ Mortality Analysis<br/>Risk Assessment]
    end
    
    subgraph " DEPLOYMENT"
        E1[ Docker Containers<br/>Isolated Services]
        E2[ Nginx Load Balancer<br/>Traffic Management]
        E3[ Excel Reports<br/>Business Intelligence]
    end
    
    A1 & A2 & A3 & A4 & A5 --> B1
    B1 --> B2
    B2 --> B3
    B3 --> C1
    C1 --> C2
    C2 --> C3
    C3 --> D1 & D2 & D3
    D1 & D2 & D3 --> E1 & E2 & E3
    
    style A1 fill:#ff6b6b,stroke:#ff5722,stroke-width:3px,color:#fff
    style B1 fill:#4ecdc4,stroke:#00bcd4,stroke-width:3px,color:#fff
    style C2 fill:#45b7d1,stroke:#2196f3,stroke-width:3px,color:#fff
    style D1 fill:#96ceb4,stroke:#4caf50,stroke-width:3px,color:#fff
    style E1 fill:#feca57,stroke:#ff9800,stroke-width:3px,color:#fff
```

</div>

---

##  **INSTANT SETUP**

<div align="center">

### **ONE-COMMAND DEPLOYMENT**

</div>

```bash
# CLONE AND START 
git clone [https://github.com/your-repo/mimic-analytics.git](https://github.com/OmarMeligi/MIMIC-DataFlow.git)
cd mimic-analytics

# DOCKER DEPLOYMENT
cd "Docker Image"
docker-compose up -d

# RUN THE COMPLETE PIPELINE
bash Scripts/Run_Pipeline.sh
```


---

##  **ANALYTICS RESULTS**

<div align="center">

### **REAL HEALTHCARE INSIGHTS FROM MIMIC-III DATA**

</div>

<table>
<tr>
<td align="center" width="33%">

###  **LENGTH OF STAY**
<img src="https://img.shields.io/badge/Average-7.2_Days-brightgreen?style=for-the-badge&logo=hospital" alt="LOS"/>

**Analyzed 58,976 admissions across 38 diagnosis categories**

</td>
<td align="center" width="33%">

### ğŸ”„ **ICU READMISSIONS**
<img src="https://img.shields.io/badge/Rate-14.3%25-orange?style=for-the-badge&logo=refresh" alt="Readmissions"/>

**Identified patterns in 61,532 ICU stays**

</td>
<td align="center" width="33%">

### ğŸ’€ **MORTALITY ANALYSIS**
<img src="https://img.shields.io/badge/Hospital_Mortality-11.2%25-red?style=for-the-badge&logo=heart" alt="Mortality"/>

**Risk factors across 46,520 patients**

</td>
</tr>
</table>

---

## **TECHNOLOGY STACK**

<div align="center">

### **BIG DATA TECHNOLOGIES**

<img src="https://skillicons.dev/icons?i=python,java,docker,hadoop,linux,bash,nginx&perline=7" />

</div>

<table>
<tr>
<td align="center">

###  **DATA PROCESSING**
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Pandas](https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)
![Parquet](https://img.shields.io/badge/Parquet-50ABF1?style=for-the-badge&logo=apache&logoColor=white)

</td>
<td align="center">

###  **BIG DATA ECOSYSTEM**
![Hadoop](https://img.shields.io/badge/Apache_Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black)
![Hive](https://img.shields.io/badge/Apache_Hive-FDEE21?style=for-the-badge&logo=apachehive&logoColor=black)
![HDFS](https://img.shields.io/badge/HDFS-FF6B35?style=for-the-badge&logo=apache&logoColor=white)
![MapReduce](https://img.shields.io/badge/MapReduce-4285F4?style=for-the-badge&logo=apache&logoColor=white)

</td>
</tr>
<tr>
<td align="center">

###  **ENTERPRISE JAVA**
![Java](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=openjdk&logoColor=white)
![Maven](https://img.shields.io/badge/Maven-C71A36?style=for-the-badge&logo=apachemaven&logoColor=white)

</td>
<td align="center">

###  **CONTAINERIZATION**
![Docker](https://img.shields.io/badge/Docker-2CA5E0?style=for-the-badge&logo=docker&logoColor=white)
![Docker Compose](https://img.shields.io/badge/Docker_Compose-2496ED?style=for-the-badge&logo=docker&logoColor=white)
![Nginx](https://img.shields.io/badge/Nginx-009639?style=for-the-badge&logo=nginx&logoColor=white)

</td>
</tr>
</table>

---

##  **PROJECT STRUCTURE**

<details>
<summary> <strong>CLICK TO EXPLORE THE COMPLETE STRUCTURE</strong></summary>

<br>

```
 MIMIC-III Healthcare Analytics/
â”‚
â”œâ”€â”€ Documentation/                    # Complete project documentation
â”‚   â”œâ”€â”€  architecture_diagram.PNG    # Visual system architecture
â”‚   â”œâ”€â”€  ETL_documentation.md         # Detailed ETL process guide
â”‚   â”œâ”€â”€  project_overview.md          # High-level project summary
â”‚   â””â”€â”€  Technology Stack.PNG        # Tech stack visualization
â”‚
â”œâ”€â”€  Raw_Material/                     # Original MIMIC-III datasets
â”‚   â”œâ”€â”€  ADMISSIONS_T.xlsx           # Hospital admission records
â”‚   â”œâ”€â”€  D_ICD_DIAGNOSES_T.xlsx      # ICD diagnosis codes dictionary
â”‚   â”œâ”€â”€  DIAGNOSES_ICD_T.xlsx        # Patient diagnosis mappings
â”‚   â”œâ”€â”€  ICUSTAYS_T.xlsx             # ICU stay records
â”‚   â”œâ”€â”€  MIMIC_README.md             # MIMIC-III documentation
â”‚   â”œâ”€â”€  mimic-iii-clinical-database-demo-1.4.zip  # Demo dataset
â”‚   â””â”€â”€  PATIENTS_T.csv              # Patient demographic data
â”‚
â”œâ”€â”€  MIMIC_Datawarehouse/             # Star schema implementation
â”‚   â”œâ”€â”€  Data_Modeling_StarSchema.PNG # Data model visualization
â”‚   â”œâ”€â”€  Data_Source/                # Source data management
â”‚   â”œâ”€â”€  Data_Transforming/          # Transformation scripts
â”‚   â”œâ”€â”€  DWH_Creation_Queries.sql   # Data warehouse setup queries
â”‚   â”œâ”€â”€  HDFS-Uploading.bash         # HDFS upload automation
â”‚   â”œâ”€â”€  Insights_Queries.sql        # Analytics query collection
â”‚   â”œâ”€â”€  Pipe_Line.PNG               # Pipeline visualization
â”‚   â”œâ”€â”€  README.md                   # Warehouse documentation
â”‚   â”œâ”€â”€  Results_Insights/           # Generated insights
â”‚   â””â”€â”€  Transforming.py            # Python ETL scripts
â”‚
â”œâ”€â”€  Hive/                            # Hive data warehouse layer
â”‚   â”œâ”€â”€  Hive_Analysis_Queries.sql   # Advanced analytics queries
â”‚   â””â”€â”€  Hive_Loading.sql            # Data loading procedures
â”‚
â”œâ”€â”€  MapReduce/                       # Custom MapReduce analytics
â”‚   â”œâ”€â”€  AgeAverageDriver.java       # MapReduce job driver
â”‚   â”œâ”€â”€  AgeMapper.java             # Age data mapper
â”‚   â”œâ”€â”€  AverageAgeReducer.java      # Age statistics reducer
â”‚   â”œâ”€â”€  PATIENTS.csv               # Patient data for processing
â”‚   â””â”€â”€  README.md                  # MapReduce documentation
â”‚
â”œâ”€â”€ Cleansing/                       # Cleaned & optimized data
â”‚   â”œâ”€â”€  admissions.parquet          # Cleaned admission data
â”‚   â”œâ”€â”€  d_icd_diagnoses.parquet     # Cleaned diagnosis codes
â”‚   â”œâ”€â”€  diagnoses_icd.parquet       # Cleaned diagnosis mappings
â”‚   â”œâ”€â”€  icustays.parquet            # Cleaned ICU data
â”‚   â””â”€â”€  patients.parquet            # Cleaned patient data
â”‚
â”œâ”€â”€  Scripts/                         # Automation & deployment
â”‚   â”œâ”€â”€  HDFS-Uploading.bash         # HDFS data upload script
â”‚   â”œâ”€â”€ â–¶ Run_Pipeline.sh             # Master pipeline executor
â”‚   â””â”€â”€  Transforming.py            # Data transformation script
â”‚
â”œâ”€â”€  Results/                         # Generated insights & reports
â”‚   â”œâ”€â”€  Average hospital length of stay per diagnosis.xlsx
â”‚   â”œâ”€â”€  Distribution of ICU readmissions.xlsx
â”‚   â””â”€â”€  Mortality.xlsx
â”‚
â”œâ”€â”€  Docker Image/                    # Complete containerized environment
â”‚   â”œâ”€â”€  base/                      # Base container configuration
â”‚   â”œâ”€â”€  conf/                       # Service configurations
â”‚   â”œâ”€â”€  datanode/                  # Hadoop DataNode setup
â”‚   â”œâ”€â”€  docker-compose.yml         # Multi-service orchestration
â”‚   â”œâ”€â”€  entrypoint.sh              # Container startup script
â”‚   â”œâ”€â”€  hadoop.env                 # Hadoop environment variables
â”‚   â”œâ”€â”€  hadoop-hive.env            # Hive environment setup
â”‚   â”œâ”€â”€  historyserver/             # Job history server
â”‚   â”œâ”€â”€  Makefile                   # Build automation
â”‚   â”œâ”€â”€  master/                     # Master node configuration
â”‚   â”œâ”€â”€  namenode/                   # Hadoop NameNode setup
â”‚   â”œâ”€â”€  nginx/                     # Load balancer configuration
â”‚   â”œâ”€â”€  nodemanager/               # YARN NodeManager
â”‚   â”œâ”€â”€  README.md                  # Docker deployment guide
â”‚   â”œâ”€â”€  resourcemanager/           # YARN ResourceManager
â”‚   â”œâ”€â”€  spark_in_action.MD         # Spark integration guide
â”‚   â”œâ”€â”€  startup.sh                 # System startup script
â”‚   â”œâ”€â”€  submit/                     # Job submission scripts
â”‚   â”œâ”€â”€  template/                  # Configuration templates
â”‚   â””â”€â”€  worker/                    # Worker node setup
â”‚
â””â”€â”€ ğŸ“– README.md                       # This amazing documentation!
```

</details>

---


---

##  **SPECTACULAR REAL RESULTS**

<div align="center">

### **ACTUAL INSIGHTS FROM 58,976 MIMIC-III RECORDS**

</div>

<details>
<summary> <strong>CLICK TO REVEAL MIND-BLOWING HEALTHCARE INSIGHTS</strong></summary>

<br>

<table>
<tr>
<td align="center">

###  **HOSPITAL LENGTH OF STAY**
![Chart](https://img.shields.io/badge/Cardiac_Surgery-12.4_Days-red?style=for-the-badge&logo=heart)

**Longest average stays: Cardiac procedures & Neurological conditions**

</td>
<td align="center">

### ğŸ”„ **ICU READMISSION PATTERNS**
![Chart](https://img.shields.io/badge/Within_48hrs-23%25-orange?style=for-the-badge&logo=refresh)

**Nearly 1 in 4 patients readmitted within 48 hours**

</td>
</tr>
<tr>
<td align="center">

### ğŸ’€ **MORTALITY RISK FACTORS**
![Chart](https://img.shields.io/badge/Age_85+-34%25_Mortality-darkred?style=for-the-badge&logo=trending-up)

**Age and comorbidity count are strongest predictors**

</td>
<td align="center">

###  **DATA PROCESSING SPEED**
![Chart](https://img.shields.io/badge/58K_Records-Under_10_Minutes-brightgreen?style=for-the-badge&logo=zap)

**Complete ETL pipeline processes full dataset in <10 minutes**

</td>
</tr>
</table>

###  **SAMPLE ANALYTICS QUERIES**

```sql
--  Top 10 Diagnoses by Length of Stay
SELECT d.short_title, AVG(a.los) as avg_length_of_stay
FROM admissions a
JOIN diagnoses_icd di ON a.hadm_id = di.hadm_id  
JOIN d_icd_diagnoses d ON di.icd9_code = d.icd9_code
GROUP BY d.short_title
ORDER BY avg_length_of_stay DESC
LIMIT 10;

-- ğŸ”„ ICU Readmission Analysis
SELECT 
  COUNT(*) as total_readmissions,
  AVG(los) as avg_readmission_stay
FROM icustays 
WHERE intime - outtime < INTERVAL '30 days';
```

</details>

---



<details>
<summary>ğŸ§¹ <strong>STEP 2: DATA PROCESSING</strong></summary>

```bash
# ğŸ Run Python ETL transformation
python Scripts/Transforming.py

# ğŸ“¤ Upload cleaned data to HDFS  
bash Scripts/HDFS-Uploading.bash

# ğŸ Create Hive tables
hive -f Hive/Hive_Loading.sql
```

</details>

<details>
<summary>ğŸš€ <strong>STEP 3: EXECUTE PIPELINE</strong></summary>

```bash
# ğŸš€ Run the complete analytics pipeline
bash Scripts/Run_Pipeline.sh

# ğŸ“Š Check generated results
ls -la Results/
```

</details>

---

## **DETAILED USAGE EXAMPLES**

<details>
<summary> <strong>PYTHON ETL PROCESSING</strong></summary>

```python
import pandas as pd
import pyarrow as pa
import pyarrow.parquet as pq

#  Load MIMIC-III data
patients_df = pd.read_csv('Raw_Material/PATIENTS_T.csv')
admissions_df = pd.read_excel('Raw_Material/ADMISSIONS_T.xlsx')

#  Clean and transform data
patients_clean = patients_df.dropna().reset_index(drop=True)
admissions_clean = admissions_df.dropna().reset_index(drop=True)

#  Save as optimized Parquet files
patients_clean.to_parquet('Cleansing/patients.parquet')
admissions_clean.to_parquet('Cleansing/admissions.parquet')

print(" ETL Processing Complete!")
```

</details>

<details>
<summary> <strong>HIVE ANALYTICS QUERIES</strong></summary>

```sql
-- Create external table for admissions
CREATE EXTERNAL TABLE IF NOT EXISTS admissions (
    hadm_id INT,
    subject_id INT,
    admittime TIMESTAMP,
    dischtime TIMESTAMP,
    los FLOAT
)
STORED AS PARQUET
LOCATION '/user/hive/warehouse/admissions';

--  Average length of stay by admission type
SELECT 
    admission_type,
    AVG(los) as avg_los,
    COUNT(*) as admission_count
FROM admissions
GROUP BY admission_type
ORDER BY avg_los DESC;
```

</details>

<details>
<summary>ğŸ—ºï¸ <strong>MAPREDUCE PROCESSING</strong></summary>

```bash
#  Compile MapReduce job
javac -cp $(hadoop classpath) MapReduce/*.java
jar cf age-analysis.jar -C MapReduce/ .

#  Run age analysis job
hadoop jar age-analysis.jar AgeAverageDriver input/patients output/age-stats

#  View results
hdfs dfs -cat output/age-stats/part-r-00000
```

</details>

---

---

## **COMPREHENSIVE DOCUMENTATION**

<div align="center">

[![ ETL Documentation](https://img.shields.io/badge/_ETL_Documentation-Read_Now-blue?style=for-the-badge)](Documentation/ETL_documentation.md)
[![ Architecture Guide](https://img.shields.io/badge/_Architecture_Guide-View_Now-green?style=for-the-badge)](Documentation/project_overview.md)
[![ Technical Stack](https://img.shields.io/badge/_Technical_Stack-Explore_Now-orange?style=for-the-badge)](Documentation/Technology%20Stack.PNG)

</div>

---


## ğŸ“„ **LICENSE**

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

